from typing import Annotated, Type

from langchain_core.language_models import BaseChatModel
from langchain_core.messages import ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import BaseTool
from langchain_core.tools.base import InjectedToolCallId
from langgraph.types import Command
from pydantic import BaseModel, Field

from chatbot.agents.prompts import SQL_CHECK_SYSTEM_PROMPT
from chatbot.agents.reducers import Item
from chatbot.databases import BigQueryDatabase


class BaseBigQueryTool(BaseModel):
    """Base tool for interacting with a BigQuery database"""
    db: BigQueryDatabase = Field(exclude=True)

    class Config:
        arbitrary_types_allowed = True

class _ListDatasetsToolInput(BaseModel):
    tool_input: str = Field("", description="An empty string.")

class ListDatasetsTool(BaseBigQueryTool, BaseTool):
    """Tool for getting dataset names from a BigQuery project"""
    name: str = "list_datasets"
    description: str = "Input to this tool is an empty string. Output is a list of datasets and its descriptions in the project"
    args_schema: Type[BaseModel] = _ListDatasetsToolInput

    def _run(self, tool_input: str="") -> str:
        """Get the full dataset names from a BigQuery project

        Args:
            tool_input (str, optional): Does nothing. Defaults to "".

        Returns:
            str: List of dataset names and descriptions
        """
        return self.db.get_datasets_info()

class _DatasetsTablesInfoToolInput(BaseModel):
    dataset_names: str = Field(
        ...,
        description=(
            "A comma-separated list of the dataset names for which to return the tables' metadata. Example input: 'dataset1, dataset2, dataset3'"
        ),
    )

class DatasetsTablesInfoTool(BaseBigQueryTool, BaseTool):
    """Tool for getting metadata about the tables from BigQuery datasets"""
    name: str = "datasets_tables_info"
    description: str = "Input to this tool is a comma-separated list of dataset names. Output is the schema, metadata and sample rows of the tables from those datasets. Be sure that the datasets actually exist by calling list_datasets first! Example Input: 'dataset1, dataset2, dataset3'"
    args_schema: Type[BaseModel] = _DatasetsTablesInfoToolInput

    def _run(self, dataset_names: str) -> str:
        """Get the schema, metadata and sample rows from the tables of each dataset

        Args:
            dataset_names (str): Comma-separated list of dataset names

        Returns:
            str: Schema, metadata and sample rows from the tables of each dataset
        """
        return self.db.get_tables_info(dataset_names)

class _QueryCheckToolInput(BaseModel):
    query: str = Field(..., description="A detailed SQL query to be checked.")

class QueryCheckTool(BaseTool):
    """Tool for checking if a query is correct using a LLM"""
    name: str = "sql_query_check"
    description: str = "Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_query!"
    args_schema: Type[BaseModel] = _QueryCheckToolInput
    llm: BaseChatModel

    def _run(self, query: str, config: RunnableConfig) -> str:
        """Check if a SQL query is valid using a LLM

        Args:
            query (str): SQL query

        Returns:
            str: Validated SQL query, generated by the LLM
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", SQL_CHECK_SYSTEM_PROMPT),
            ("human", "{query}")
        ])
        chain = prompt | self.llm
        return chain.invoke({"query": query}, config).content

    async def _arun(self, query: str, config: RunnableConfig) -> str:
        """Asynchronously check if a SQL query is valid using a LLM

        Args:
            query (str): SQL query

        Returns:
            str: Validated SQL query, generated by the LLM
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", SQL_CHECK_SYSTEM_PROMPT),
            ("human", "{query}")
        ])
        chain = prompt | self.llm
        response = await chain.ainvoke({"query": query}, config)
        return response.content

class _QueryTableToolInput(BaseModel):
    query: str = Field(..., description="A detailed and correct SQL query.")
    tool_call_id: Annotated[str, InjectedToolCallId]

class QueryTableTool(BaseBigQueryTool, BaseTool):
    """Tool for querying a BigQuery database"""
    name: str = "sql_query"
    description: str = "Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query with the sql_query_check tool and try again."
    args_schema: Type[BaseModel] = _QueryTableToolInput

    def _run(self, query: str, tool_call_id: Annotated[str, InjectedToolCallId]) -> str:
        """Query a BigQuery table and return the output results or an error

        Args:
            query (str): SQL Query

        Returns:
            str: SQL query output results
        """
        query_results = self.db.query(query)

        return Command(
            update={
                "sql_queries": Item(content=query),
                "sql_queries_results": Item(content=query_results),
                "messages":[ToolMessage(query_results, tool_call_id=tool_call_id)]
            }
        )
